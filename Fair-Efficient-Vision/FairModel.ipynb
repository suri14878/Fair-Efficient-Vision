{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/miniconda3/envs/torch_medai/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/bin/miniconda3/envs/torch_medai/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch, json\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import models_vit\n",
    "from Dataset_Fair import build_combined_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569af9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred_probs):\n",
    "\n",
    "    y_prob = torch.softmax(y_pred_probs, dim=1)\n",
    "    y_pred = torch.argmax(y_prob, dim=1).cpu().numpy()  \n",
    "    y_true = y_true.cpu().numpy()                             \n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    try:\n",
    "        overall_unique_classes = np.unique(y_true)\n",
    "        if len(overall_unique_classes) == 2:\n",
    "            y_score_reduced = y_prob[:, overall_unique_classes[0]]\n",
    "            overall_auroc = roc_auc_score(y_true, y_score_reduced.detach().numpy())\n",
    "        if len(overall_unique_classes) >= 3:\n",
    "            y_true_onehot = label_binarize(y_true, classes=range(3))\n",
    "            overall_auroc = roc_auc_score(y_true_onehot, y_prob, multi_class='ovr', average='macro')\n",
    "        else:\n",
    "            print(\"Batch contains only one class. Setting AUROC to 0.333\")\n",
    "            overall_auroc = 0.33\n",
    "    except ValueError:\n",
    "        auroc = float('nan') \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auroc': overall_auroc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_distinct_attributes(attributes, true_labels, predicted_labels, attribute_names, attribute_values):\n",
    "    results = {attr: {value: {'accuracy': 0.0, 'precision': 0.0, 'auroc': 0.0, 'count': 0} \n",
    "                      for value in values} \n",
    "               for attr, values in attribute_values.items()}\n",
    "    \n",
    "    overall_correct = 0\n",
    "    total_samples = true_labels.size(0)\n",
    "\n",
    "    all_true_labels = true_labels.detach().numpy()\n",
    "    predicted_labels = torch.softmax(predicted_labels, dim=1).detach()\n",
    "    all_predicted_probs = torch.argmax(predicted_labels, dim=1).detach().numpy()  \n",
    "    for attr_idx, attr_name in enumerate(attribute_names):\n",
    "        for value in attribute_values[attr_name]:\n",
    "              indices = (attributes[:, attr_idx] == value).nonzero(as_tuple=True)[0]\n",
    "            if indices.numel() > 0:  \n",
    "                \n",
    "                subset_true_labels = all_true_labels[indices]\n",
    "                subset_predicted_labels = all_predicted_probs[indices]\n",
    "                \n",
    "                if np.ndim(subset_predicted_labels) == 0: \n",
    "                    subset_predicted_labels = np.array([subset_predicted_labels])\n",
    "                \n",
    "                if np.ndim(subset_true_labels) == 0: \n",
    "                    subset_true_labels = np.array([subset_true_labels])\n",
    "\n",
    "                # Compute metrics\n",
    "                accuracy = accuracy_score(subset_true_labels, subset_predicted_labels)\n",
    "                precision = precision_score(subset_true_labels, subset_predicted_labels, average='weighted',zero_division=0)\n",
    "                unique_classes = np.unique(subset_true_labels)\n",
    "\n",
    "                if len(unique_classes) == 2:\n",
    "                    y_score_reduced = predicted_labels[indices][:, unique_classes[0]]# y_score_reduced.detach().numpy()[:, 1]\n",
    "                    auroc = roc_auc_score(subset_true_labels, y_score_reduced.detach().numpy(), multi_class='ovr', average='macro')\n",
    "                if len(unique_classes) >= 3:\n",
    "                    y_true_onehot = label_binarize(subset_true_labels, classes=[0, 1, 2])\n",
    "\n",
    "                    auroc = roc_auc_score(y_true_onehot, predicted_labels[indices].detach().numpy(), multi_class='ovr', average='macro')\n",
    "                else:\n",
    "                    # Assign a default AUROC value when only one class is present\n",
    "                    print(\"Batch contains only one class. Setting AUROC to 0.333\")\n",
    "                    auroc = 0.33\n",
    "                # Store results\n",
    "                results[attr_name][value]['accuracy'] += accuracy\n",
    "                results[attr_name][value]['precision'] += precision\n",
    "                results[attr_name][value]['auroc'] += auroc\n",
    "                results[attr_name][value]['count'] += indices.size(0)\n",
    "            \n",
    "    overall_results = {}\n",
    "    for attr, values in results.items():\n",
    "        overall_results[attr] = {}\n",
    "        for value, metrics in values.items():\n",
    "            if metrics['count'] > 0: \n",
    "                overall_results[attr][value] = {\n",
    "                    'accuracy': metrics['accuracy'],\n",
    "                    'precision': metrics['precision'],\n",
    "                    'auroc': metrics['auroc'],\n",
    "                    'count': metrics['count'],\n",
    "                }\n",
    "\n",
    "    return overall_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_dist(A, B, cosine=False, eps=1e-10):\n",
    "        A_n = (A ** 2).sum(axis=1).reshape(-1, 1)\n",
    "        B_n = (B ** 2).sum(axis=1).reshape(1, -1)\n",
    "        inner = np.matmul(A, B.T)\n",
    "        if cosine:\n",
    "            return 1 - inner / (np.sqrt(A_n * B_n) + eps)\n",
    "        else:\n",
    "            return A_n - 2 * inner + B_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def Fair_predicted_output(predicted_tensor, pooled_embeddings, attributes_tensor, tau_values, theta_values, lambda_GLIF_NRW=0.001):\n",
    "    \"\"\"\n",
    "    Fairness post-processing function that considers all demographics at once and applies class-specific tau and theta.\n",
    "    \n",
    "    Args:\n",
    "        predicted_tensor (Tensor): Raw predicted values (logits or class predictions).\n",
    "        pooled_embeddings (Tensor): Embeddings for each instance.\n",
    "        attributes_tensor (Tensor): Tensor containing sensitive attributes (e.g., gender, race, etc.).\n",
    "        sensitive_attribute_indices (list): List of indices for the sensitive attributes to use for fairness.\n",
    "        tau_values (dict): Dictionary with tau values for each class {class: tau}.\n",
    "        theta_values (dict): Dictionary with theta values for each class {class: theta}.\n",
    "        lambda_GLIF_NRW (float): Regularization parameter for the fairness adjustment.\n",
    "\n",
    "    Returns:\n",
    "        y_updated (Tensor): Updated predictions after fairness adjustment.\n",
    "    \"\"\"\n",
    "    all_embeddings = pooled_embeddings.detach()\n",
    "    sensitive_attributes = np.array(attributes_tensor)\n",
    "    \n",
    "    one_hot_list = []\n",
    "\n",
    "    for attr_idx in range(attributes_tensor.shape[1]):\n",
    "        num_classes = np.max(sensitive_attributes[:, attr_idx]) + 1\n",
    "        one_hot = np.eye(num_classes)[sensitive_attributes[:, attr_idx]]\n",
    "        one_hot_list.append(torch.tensor(one_hot, dtype=torch.float32))\n",
    "    \n",
    "    one_hot_sensitive = torch.cat(one_hot_list, dim=1)\n",
    "    \n",
    "    prohibited_subspace = one_hot_sensitive.T @ pooled_embeddings\n",
    "    one_hot_column = one_hot_sensitive.shape[1]\n",
    "    \n",
    "    tSVD = TruncatedSVD(n_components=one_hot_column)\n",
    "    tSVD.fit(prohibited_subspace)\n",
    "    svd_sens_directions = tSVD.components_\n",
    "    svd_sens_directions = torch.tensor(svd_sens_directions).float()\n",
    "\n",
    "    basis = svd_sens_directions.cpu().numpy().T\n",
    "    proj = np.linalg.inv(np.matmul(basis.T, basis))\n",
    "    proj = np.matmul(basis, proj)\n",
    "    proj = np.matmul(proj, basis.T)\n",
    "    proj_compl = np.eye(proj.shape[0]) - proj\n",
    "    proj_compl = torch.tensor(proj_compl).float().to('cpu')\n",
    "\n",
    "    fair_space_data = all_embeddings @ proj_compl.T\n",
    "    fair_space_data = fair_space_data.cpu().numpy()\n",
    "\n",
    "    fair_space_data_squared_distances = e_dist(fair_space_data, fair_space_data, cosine=True)\n",
    "    fair_space_data_squared_distances = torch.relu(torch.tensor(fair_space_data_squared_distances).to('cpu'))\n",
    "    \n",
    "    fair_similarity_W = torch.zeros_like(fair_space_data_squared_distances)\n",
    "\n",
    "    for idx, label in enumerate(predicted_tensor):\n",
    "        class_tau = tau_values[label.item()]  \n",
    "        class_theta = theta_values[label.item()] \n",
    "        fair_similarity_W[idx] = torch.exp(-fair_space_data_squared_distances[idx] * class_theta) * \\\n",
    "                                 (fair_space_data_squared_distances[idx] <= class_tau).float()\n",
    "\n",
    "    D_ii = torch.diag_embed(fair_similarity_W.sum(1))\n",
    "    D_ii_to_minus_half = torch.diag_embed(fair_similarity_W.sum(1).pow(-.5))\n",
    "    W_tilde = D_ii_to_minus_half @ fair_similarity_W @ D_ii_to_minus_half\n",
    "    D_tilde_to_minus_one = torch.diag_embed(W_tilde.sum(1).pow(-1))\n",
    "    W = D_tilde_to_minus_one @ W_tilde\n",
    "    L = torch.eye(D_ii.shape[0]) - W\n",
    "    L = (L.T + L) / 2\n",
    "\n",
    "    matrix_to_invert = lambda_GLIF_NRW * L + torch.eye(L.shape[0])\n",
    "    condition_number = torch.linalg.cond(matrix_to_invert)\n",
    "    \n",
    "    avg_degree = fair_similarity_W.sum(1).mean()\n",
    "    y_updated = torch.inverse(lambda_GLIF_NRW * avg_degree * L + torch.eye(L.shape[0])) @ predicted_tensor\n",
    "    y_updated = torch.clamp(y_updated, min=-10, max=10)\n",
    "\n",
    "    return y_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc503a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_dict(dictionary , file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f8ae03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eav(Fair_record):\n",
    "    overall_accuracy = 0.0\n",
    "    overall_precision = 0.0\n",
    "    overall_auroc = 0.0\n",
    "    for batch_no in range(len(Fair_record)):\n",
    "        overall_accuracy += Fair_record[str(batch_no)]['Overall']['accuracy']\n",
    "        overall_precision += Fair_record[str(batch_no)]['Overall']['precision']\n",
    "        overall_auroc += Fair_record[str(batch_no)]['Overall']['auroc']\n",
    "\n",
    "    print(\"Overall Accuracy : \" + str(overall_accuracy/len(Fair_record)))\n",
    "    print(\"Overall Precision : \" + str(overall_precision/len(Fair_record)))\n",
    "    print(\"Overall AUROC : \" + str(overall_auroc/len(Fair_record)))\n",
    "    \n",
    "    record = {'race' : {0 : [], 1 : [], 2: []},\n",
    "               'male' : {0 : [], 1 : []}, \n",
    "               'hispanic' : {0 : [], 1 : []}, \n",
    "               'maritalstatus' : {-1 : [], 0 : [], 1 : [], 2: [],3 : [], 4 : []}, \n",
    "               'language' : {0 : [], 1 : [], 2: []}\n",
    "              }\n",
    "\n",
    "    for batch_no in range(len(Fair_record)):\n",
    "        for attribute in attribute_names:\n",
    "            temp_record = Fair_record[str(batch_no)][attribute]\n",
    "            for value in temp_record.keys():\n",
    "                record[attribute][int(value)].append(temp_record[value])\n",
    "    sum_record =  {'race' : {0 : {}, 1 : {}, 2: {}},\n",
    "               'male' : {0 : {}, 1 : {}}, \n",
    "               'hispanic' : {0 : {}, 1 : {}}, \n",
    "               'maritalstatus' : {-1 : {}, 0 : {}, 1 : {}, 2: {},3 : {}, 4 : {}}, \n",
    "               'language' : {0 : {}, 1 : {}, 2: {}}\n",
    "              }\n",
    "\n",
    "    for attribute in record.keys(): \n",
    "        for value in record[attribute].keys():\n",
    "            temp_record = record[attribute][value]\n",
    "            count = 0\n",
    "            temp_acc = 0.0\n",
    "            temp_prec = 0.0\n",
    "            temp_auroc = 0.0\n",
    "            for temp_matrix in temp_record:\n",
    "                temp_acc += temp_matrix['accuracy'] * temp_matrix['count'] \n",
    "                temp_prec += temp_matrix['precision'] * temp_matrix['count'] \n",
    "                temp_auroc += temp_matrix['auroc'] * temp_matrix['count']\n",
    "                count += temp_matrix['count']\n",
    "    #             record[attribute][int(value)].append(temp_record[value])\n",
    "            if count > 0 : \n",
    "                sum_record[attribute][value] = {\"accuracy\" : temp_acc/count, \n",
    "                                                \"precision\" : temp_prec/count , \n",
    "                                                \"auroc\" : temp_auroc/count}\n",
    "            else:\n",
    "                print(f\"Count is 0 for attribute :  {attribute} , category : {value}\")\n",
    "    return sum_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83401ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Fair_file_path = './Fair_Performance_record.json'\n",
    "Original_file_path = './Performance_record.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ee262",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dirs1 = './Glaucoma/'\n",
    "root_dirs2 = './DR/'\n",
    "root_dirs = [root_dirs1, root_dirs2]\n",
    "test_dataset = build_combined_dataset(root_dirs=root_dirs, phase='test', input_size=200)\n",
    "test_loader = DataLoader(test_dataset,batch_size=500,pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6fe6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Pooling Current State : True\n",
      "1000\n",
      "LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "Position interpolate from 14x14 to 12x12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (head_drop): Dropout(p=0, inplace=False)\n",
       "  (project_layer): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models_vit.load_pretrained_vit_base(target_size=200,global_pool=True, num_classes=3)\n",
    "custom_weights = torch.load('./best_student_model.pth', map_location='cpu')  # Adjust map_location if using GPU\n",
    "model.load_state_dict(custom_weights, strict=False)\n",
    "# model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9110cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names = ['race','male', 'hispanic', 'maritalstatus', 'language']\n",
    "attribute_values = { \n",
    "   'race': [0, 1, 2],\n",
    "    'male': [0, 1],\n",
    "    'language': [0, 1, 2],\n",
    "    'hispanic': [0, 1],\n",
    "    'maritalstatus': [-1,0, 1,2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6797b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8662)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8686)\n",
      "tensor(0.)\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8726)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8321)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.9171)\n",
      "tensor(0.)\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8234)\n",
      "tensor(0.)\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8983)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.9171)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8779)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8605)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8417)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8761)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n"
     ]
    }
   ],
   "source": [
    "Fair_result = {}\n",
    "original_result = {}\n",
    "class_specific_tau = {0: 0.8, 1: 1.1, 2: 1.4}  # Adjust these values based on your requirements\n",
    "class_specific_theta = {0: 0.001, 1: 0.002, 2: 0.015} # Adjust these values based on your requirements\n",
    "for batch_no,(data, labels, attributes) in enumerate(test_loader):\n",
    "    print(\"Prediction start from the model\")\n",
    "    with torch.no_grad():\n",
    "        Embedding = model.get_spatial_feature_maps(data)\n",
    "        pooled_embeddings = F.adaptive_avg_pool2d(Embedding, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "        predicted_tensor,_ = model(data)\n",
    "    temp_dict_fair = dict()\n",
    "    temp_dict_original = dict()\n",
    "    print(\"Prediction recieved from the model\")\n",
    "    fair_output = Fair_predicted_output(predicted_tensor, pooled_embeddings, attributes, \n",
    "                                            class_specific_tau, class_specific_theta, lambda_GLIF_NRW=0.001)\n",
    "    attribute_value = {Attibute : attribute_values[attribute_names[attribute_no]]}\n",
    "\n",
    "    overall_results = evaluate_distinct_attributes(attributes, labels, predicted_tensor, attribute_names, attribute_values)\n",
    "    F_overall_results = evaluate_distinct_attributes(attributes, labels, fair_output, attribute_names, attribute_values)\n",
    "    temp_dict_fair.update(F_overall_results)\n",
    "    temp_dict_original.update(overall_results)\n",
    "    Fair_overall_result = calculate_metrics(labels.detach(), fair_output.detach())\n",
    "    UnFair_overall_result = calculate_metrics(labels.detach(), predicted_tensor.detach())\n",
    "    temp_dict_fair['Overall'] = Fair_overall_result\n",
    "    temp_dict_original['Overall'] = UnFair_overall_result\n",
    "    Fair_result[batch_no] = temp_dict_fair\n",
    "    original_result[batch_no] = temp_dict_original\n",
    "    save_dict(Fair_result, Fair_file_path)\n",
    "    save_dict(original_result, Original_file_path)\n",
    "    Fair_record = load_dict(Fair_file_path)\n",
    "    Original_record = load_dict(Original_file_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26497f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy : 0.7273333333333332\n",
      "Overall Precision : 0.7573536886596446\n",
      "Overall AUROC : 0.8761363922374534\n",
      "Overall Accuracy : 0.7373333333333334\n",
      "Overall Precision : 0.7330731135574499\n",
      "Overall AUROC : 0.8573694796703628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'race_0': [0.8945186353556517, 0.8777567362332971],\n",
       " 'race_1': [0.8675337262798222, 0.8470081060197792],\n",
       " 'race_2': [0.8747767373519817, 0.8559381871782273],\n",
       " 'male_0': [0.8744718537618532, 0.8555479442771696],\n",
       " 'male_1': [0.8772443784881646, 0.8585984871608685],\n",
       " 'hispanic_0': [0.8765793351579889, 0.8577618796304949],\n",
       " 'hispanic_1': [0.8502193406340489, 0.8326452587762472],\n",
       " 'maritalstatus_-1': [0.8669838227737584, 0.8467761740686974],\n",
       " 'maritalstatus_0': [0.8826708300718905, 0.8650800904153172],\n",
       " 'maritalstatus_1': [0.8655562495211385, 0.8448161540305714],\n",
       " 'maritalstatus_2': [0.8943512996168117, 0.8751783985508284],\n",
       " 'maritalstatus_3': [0.8700527501532159, 0.8481969500546621],\n",
       " 'maritalstatus_4': [0.5046367521367521, 0.5046367521367521],\n",
       " 'language_0': [0.8759793236347047, 0.85713702110791],\n",
       " 'language_1': [0.7715398308856254, 0.756928991742076],\n",
       " 'language_2': [0.8798126523651418, 0.8613928033459316]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fair_record = load_dict(Fair_file_path)\n",
    "fair_res = eav(Fair_record)\n",
    "Original_record = load_dict(Original_file_path)\n",
    "res = eav(Original_record)\n",
    "\n",
    "\n",
    "compile_res = {}\n",
    "for attribute in fair_res.keys():\n",
    "    for value in fair_res[attribute].keys():\n",
    "        if bool(fair_res[attribute][value]) and bool(res[attribute][value]):\n",
    "            compile_res[attribute + \"_\" + str(value)] = [fair_res[attribute][value]['auroc'],res[attribute][value]['auroc']]\n",
    "            \n",
    "compile_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1794f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e54113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
