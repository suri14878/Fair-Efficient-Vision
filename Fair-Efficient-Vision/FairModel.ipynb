{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5bec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/miniconda3/envs/torch_medai/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/bin/miniconda3/envs/torch_medai/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch, json\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import models_vit\n",
    "from Dataset_Fair import build_combined_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "# from Main import calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569af9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred_probs):\n",
    "\n",
    "    y_prob = torch.softmax(y_pred_probs, dim=1)\n",
    "    y_pred = torch.argmax(y_prob, dim=1).cpu().numpy()  \n",
    "    y_true = y_true.cpu().numpy()                             \n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    try:\n",
    "        overall_unique_classes = np.unique(y_true)\n",
    "        if len(overall_unique_classes) == 2:\n",
    "            y_score_reduced = y_prob[:, overall_unique_classes[0]]\n",
    "            overall_auroc = roc_auc_score(y_true, y_score_reduced.detach().numpy())\n",
    "        if len(overall_unique_classes) >= 3:\n",
    "            y_true_onehot = label_binarize(y_true, classes=range(3))\n",
    "            overall_auroc = roc_auc_score(y_true_onehot, y_prob, multi_class='ovr', average='macro')\n",
    "        else:\n",
    "            print(\"Batch contains only one class. Setting AUROC to 0.333\")\n",
    "            overall_auroc = 0.33\n",
    "    except ValueError:\n",
    "        auroc = float('nan') \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auroc': overall_auroc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35c1921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_distinct_attributes(attributes, true_labels, predicted_labels, attribute_names, attribute_values):\n",
    "    \"\"\"\n",
    "    Evaluate metrics for each distinct value of each attribute and overall metrics including AUROC.\n",
    "    \n",
    "    Args:\n",
    "        attributes (torch.Tensor): Tensor of shape [batch_size, num_attributes], containing attributes.\n",
    "        true_labels (torch.Tensor): Ground truth labels of shape [batch_size].\n",
    "        predicted_labels (torch.Tensor): Predicted labels of shape [batch_size].\n",
    "        attribute_names (list[str]): List of attribute names (e.g., ['race', 'gender', ...]).\n",
    "        attribute_values (dict): Dictionary mapping attribute names to their distinct values.\n",
    "                                 Example: {'race': [0, 1, 2], 'gender': [0, 1], ...}.\n",
    "    \n",
    "    Returns:\n",
    "        results (dict): Dictionary containing metrics for each distinct value of each attribute.\n",
    "        overall_results (dict): Aggregated metrics for each distinct value across all attributes.\n",
    "        overall_auroc (float): Overall AUROC for the entire dataset.\n",
    "    \"\"\"\n",
    "    # Initialize results for distinct values of each attribute\n",
    "    results = {attr: {value: {'accuracy': 0.0, 'precision': 0.0, 'auroc': 0.0, 'count': 0} \n",
    "                      for value in values} \n",
    "               for attr, values in attribute_values.items()}\n",
    "    \n",
    "    overall_correct = 0\n",
    "    total_samples = true_labels.size(0)\n",
    "\n",
    "    # Collect all true labels and predicted probabilities for overall AUROC calculation\n",
    "    all_true_labels = true_labels.detach().numpy()\n",
    "    predicted_labels = torch.softmax(predicted_labels, dim=1).detach()\n",
    "    all_predicted_probs = torch.argmax(predicted_labels, dim=1).detach().numpy()  # Assuming predicted_labels are probabilities for AUROC\n",
    "    # Iterate through attributes\n",
    "    for attr_idx, attr_name in enumerate(attribute_names):\n",
    "        for value in attribute_values[attr_name]:\n",
    "            # Get indices where the current attribute equals the current value\n",
    "            indices = (attributes[:, attr_idx] == value).nonzero(as_tuple=True)[0]\n",
    "#             print(indices)\n",
    "            if indices.numel() > 0:  # Compute metrics only if there are samples for this value\n",
    "                # Get true and predicted labels for the subset\n",
    "                subset_true_labels = all_true_labels[indices]\n",
    "                subset_predicted_labels = all_predicted_probs[indices]\n",
    "                \n",
    "                if np.ndim(subset_predicted_labels) == 0:  # This checks if it is a scalar\n",
    "                    subset_predicted_labels = np.array([subset_predicted_labels])\n",
    "                \n",
    "                if np.ndim(subset_true_labels) == 0:  # This checks if it is a scalar\n",
    "                    subset_true_labels = np.array([subset_true_labels])\n",
    "#                 subset_true_labels = subset_true_labels.detach().numpy()\n",
    "#                 subset_predicted_labels = subset_predicted_labels.detach().numpy()\n",
    "#                 print(\"subset_true_labels : \" + str(subset_true_labels))\n",
    "#                 print(\"subset_pred_labels : \" + str(subset_predicted_labels))\n",
    "                # Compute metrics\n",
    "                accuracy = accuracy_score(subset_true_labels, subset_predicted_labels)\n",
    "                precision = precision_score(subset_true_labels, subset_predicted_labels, average='weighted',zero_division=0)\n",
    "                unique_classes = np.unique(subset_true_labels)\n",
    "#                 print(\"Unique_Class : \" + str(unique_classes))\n",
    "#                 print((subset_true_labels))\n",
    "#                 print((y_score_reduced))\n",
    "#                 n_classes = subset_true_labels.shape[1]\n",
    "                if len(unique_classes) == 2:\n",
    "                    # Binary classification\n",
    "                    # Use only the positive class probabilities\n",
    "                    y_score_reduced = predicted_labels[indices][:, unique_classes[0]]# y_score_reduced.detach().numpy()[:, 1]\n",
    "#                     print(subset_true_labels)\n",
    "#                     print(y_score_reduced)\n",
    "                    auroc = roc_auc_score(subset_true_labels, y_score_reduced.detach().numpy(), multi_class='ovr', average='macro')\n",
    "                if len(unique_classes) >= 3:\n",
    "                    # Multi-class classification\n",
    "                    # Convert true labels to one-hot encoded format\n",
    "                    y_true_onehot = label_binarize(subset_true_labels, classes=[0, 1, 2])\n",
    "#                     print(torch.argmax(predicted_labels[indices], dim=1).detach().numpy())\n",
    "#                     print(y_true_onehot)\n",
    "#                     print(predicted_labels[indices].detach().numpy())\n",
    "#                     y_true_onehot = np.eye(3)[subset_true_labels]\n",
    "                    # Compute ROC AUC score\n",
    "#                     print(\"Unique_Class : \" + str(np.unique(y_true_onehot)))\n",
    "#                     print(\"y_true : \" + str(y_true_onehot.shape))\n",
    "#                     print(\"predicted : \" + str(predicted_labels[indices].detach().numpy().shape))\n",
    "                    auroc = roc_auc_score(y_true_onehot, predicted_labels[indices].detach().numpy(), multi_class='ovr', average='macro')\n",
    "#                 auroc = roc_auc_score(subset_true_labels, y_score_reduced.detach().numpy(), multi_class='ovr' if len(unique_classes) > 1 else 'raise' ) if len(set(subset_true_labels)) > 1 else 0.0\n",
    "                else:\n",
    "                    # Assign a default AUROC value when only one class is present\n",
    "                    print(\"Batch contains only one class. Setting AUROC to 0.333\")\n",
    "                    auroc = 0.33\n",
    "                # Store results\n",
    "                results[attr_name][value]['accuracy'] += accuracy\n",
    "                results[attr_name][value]['precision'] += precision\n",
    "                results[attr_name][value]['auroc'] += auroc\n",
    "                results[attr_name][value]['count'] += indices.size(0)\n",
    "            \n",
    "            # Accumulate overall correct predictions\n",
    "            \n",
    "#             overall_correct += (torch.argmax(predicted_labels[indices], dim=1) == true_labels[indices]).sum().item()\n",
    "    \n",
    "    # Compute overall metrics\n",
    "    overall_results = {}\n",
    "    for attr, values in results.items():\n",
    "        overall_results[attr] = {}\n",
    "        for value, metrics in values.items():\n",
    "            if metrics['count'] > 0:  # Avoid division by zero\n",
    "                overall_results[attr][value] = {\n",
    "                    'accuracy': metrics['accuracy'],\n",
    "                    'precision': metrics['precision'],\n",
    "                    'auroc': metrics['auroc'],\n",
    "                    'count': metrics['count'],\n",
    "                }\n",
    "\n",
    "    # Compute overall AUROC\n",
    "#     overall_unique_classes = np.unique(all_true_labels)\n",
    "#     if len(overall_unique_classes) == 2:\n",
    "#         y_score_reduced = predicted_labels[:, unique_classes[0]]\n",
    "#         overall_auroc = roc_auc_score(all_true_labels, y_score_reduced.detach().numpy())\n",
    "#     if len(np.unique(all_true_labels)) >= 3:\n",
    "#         y_true_onehot = label_binarize(all_true_labels, classes=range(3))\n",
    "#         overall_auroc = roc_auc_score(y_true_onehot, predicted_labels, multi_class='ovr', average='macro')\n",
    "#     else:\n",
    "#         # Assign a default AUROC value when only one class is present\n",
    "#         print(\"Batch contains only one class. Setting AUROC to 0.333\")\n",
    "#         overall_auroc = 0.33\n",
    "#     overall_auroc = roc_auc_score(all_true_labels, predicted_labels.detach().numpy(), multi_class='ovr') if len(set(all_true_labels)) > 1 else 0.333\n",
    "\n",
    "#     overall_accuracy = overall_correct / total_samples\n",
    "#     overall_results['overall_auroc'] = overall_auroc\n",
    "#     overall_results['overall_accuracy'] = overall_accuracy\n",
    "#     print(overall_results)\n",
    "    return overall_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_dist(A, B, cosine=False, eps=1e-10):\n",
    "        A_n = (A ** 2).sum(axis=1).reshape(-1, 1)\n",
    "        B_n = (B ** 2).sum(axis=1).reshape(1, -1)\n",
    "        inner = np.matmul(A, B.T)\n",
    "        if cosine:\n",
    "            return 1 - inner / (np.sqrt(A_n * B_n) + eps)\n",
    "        else:\n",
    "            return A_n - 2 * inner + B_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def Fair_predicted_output(labels, predicted_tensor, pooled_embeddings, attributes_tensor, tau_values, theta_values, lambda_GLIF_NRW=0.001):\n",
    "    \"\"\"\n",
    "    Fairness post-processing function that considers all demographics at once and applies class-specific tau and theta.\n",
    "    \n",
    "    Args:\n",
    "        labels (Tensor): Ground truth labels for the samples.\n",
    "        predicted_tensor (Tensor): Raw predicted values (logits or class predictions).\n",
    "        pooled_embeddings (Tensor): Embeddings for each instance.\n",
    "        attributes_tensor (Tensor): Tensor containing sensitive attributes (e.g., gender, race, etc.).\n",
    "        sensitive_attribute_indices (list): List of indices for the sensitive attributes to use for fairness.\n",
    "        tau_values (dict): Dictionary with tau values for each class {class: tau}.\n",
    "        theta_values (dict): Dictionary with theta values for each class {class: theta}.\n",
    "        lambda_GLIF_NRW (float): Regularization parameter for the fairness adjustment.\n",
    "\n",
    "    Returns:\n",
    "        y_updated (Tensor): Updated predictions after fairness adjustment.\n",
    "    \"\"\"\n",
    "    all_embeddings = pooled_embeddings.detach()\n",
    "    sensitive_attributes = np.array(attributes_tensor)\n",
    "    \n",
    "    one_hot_list = []\n",
    "    \n",
    "    # Loop over the sensitive attributes indices and one-hot encode each attribute\n",
    "    for attr_idx in range(attributes_tensor.shape[1]):\n",
    "        num_classes = np.max(sensitive_attributes[:, attr_idx]) + 1\n",
    "        one_hot = np.eye(num_classes)[sensitive_attributes[:, attr_idx]]\n",
    "        one_hot_list.append(torch.tensor(one_hot, dtype=torch.float32))\n",
    "    \n",
    "    # Concatenate the one-hot encodings along the second axis (axis=1)\n",
    "    one_hot_sensitive = torch.cat(one_hot_list, dim=1)\n",
    "    \n",
    "    # Step 3: Compute the prohibited subspace (fairness space) based on sensitive attributes\n",
    "    prohibited_subspace = one_hot_sensitive.T @ pooled_embeddings\n",
    "    one_hot_column = one_hot_sensitive.shape[1]\n",
    "    \n",
    "    # Step 4: Apply SVD for dimensionality reduction\n",
    "    tSVD = TruncatedSVD(n_components=one_hot_column)\n",
    "    tSVD.fit(prohibited_subspace)\n",
    "    svd_sens_directions = tSVD.components_\n",
    "    svd_sens_directions = torch.tensor(svd_sens_directions).float()\n",
    "\n",
    "    basis = svd_sens_directions.cpu().numpy().T\n",
    "    proj = np.linalg.inv(np.matmul(basis.T, basis))\n",
    "    proj = np.matmul(basis, proj)\n",
    "    proj = np.matmul(proj, basis.T)\n",
    "    proj_compl = np.eye(proj.shape[0]) - proj\n",
    "    proj_compl = torch.tensor(proj_compl).float().to('cpu')\n",
    "\n",
    "    fair_space_data = all_embeddings @ proj_compl.T\n",
    "    fair_space_data = fair_space_data.cpu().numpy()\n",
    "\n",
    "    fair_space_data_squared_distances = e_dist(fair_space_data, fair_space_data, cosine=True)\n",
    "    fair_space_data_squared_distances = torch.relu(torch.tensor(fair_space_data_squared_distances).to('cpu'))\n",
    "    \n",
    "    fair_similarity_W = torch.zeros_like(fair_space_data_squared_distances)\n",
    "\n",
    "    for idx, label in enumerate(labels):\n",
    "        # Get class-specific tau and theta values\n",
    "        class_tau = tau_values[label.item()]  \n",
    "        class_theta = theta_values[label.item()] \n",
    "        fair_similarity_W[idx] = torch.exp(-fair_space_data_squared_distances[idx] * class_theta) * \\\n",
    "                                 (fair_space_data_squared_distances[idx] <= class_tau).float()\n",
    "\n",
    "    D_ii = torch.diag_embed(fair_similarity_W.sum(1))\n",
    "    D_ii_to_minus_half = torch.diag_embed(fair_similarity_W.sum(1).pow(-.5))\n",
    "    W_tilde = D_ii_to_minus_half @ fair_similarity_W @ D_ii_to_minus_half\n",
    "    D_tilde_to_minus_one = torch.diag_embed(W_tilde.sum(1).pow(-1))\n",
    "    W = D_tilde_to_minus_one @ W_tilde\n",
    "    L = torch.eye(D_ii.shape[0]) - W\n",
    "    L = (L.T + L) / 2\n",
    "\n",
    "    matrix_to_invert = lambda_GLIF_NRW * L + torch.eye(L.shape[0])\n",
    "    condition_number = torch.linalg.cond(matrix_to_invert)\n",
    "    \n",
    "    avg_degree = fair_similarity_W.sum(1).mean()\n",
    "    y_updated = torch.inverse(lambda_GLIF_NRW * avg_degree * L + torch.eye(L.shape[0])) @ predicted_tensor\n",
    "    y_updated = torch.clamp(y_updated, min=-10, max=10)\n",
    "\n",
    "    return y_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc503a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        return {} # Return empty dictionary if file doesn't exist\n",
    "\n",
    "# Function to save the dictionary to a file\n",
    "def save_dict(dictionary , file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f8ae03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eav(Fair_record):\n",
    "    overall_accuracy = 0.0\n",
    "    overall_precision = 0.0\n",
    "    overall_auroc = 0.0\n",
    "    for batch_no in range(len(Fair_record)):\n",
    "        overall_accuracy += Fair_record[str(batch_no)]['Overall']['accuracy']\n",
    "        overall_precision += Fair_record[str(batch_no)]['Overall']['precision']\n",
    "        overall_auroc += Fair_record[str(batch_no)]['Overall']['auroc']\n",
    "\n",
    "    print(\"Overall Accuracy : \" + str(overall_accuracy/len(Fair_record)))\n",
    "    print(\"Overall Precision : \" + str(overall_precision/len(Fair_record)))\n",
    "    print(\"Overall AUROC : \" + str(overall_auroc/len(Fair_record)))\n",
    "    \n",
    "    record = {'race' : {0 : [], 1 : [], 2: []},\n",
    "               'male' : {0 : [], 1 : []}, \n",
    "               'hispanic' : {0 : [], 1 : []}, \n",
    "               'maritalstatus' : {-1 : [], 0 : [], 1 : [], 2: [],3 : [], 4 : []}, \n",
    "               'language' : {0 : [], 1 : [], 2: []}\n",
    "              }\n",
    "\n",
    "    for batch_no in range(len(Fair_record)):\n",
    "        for attribute in attribute_names:\n",
    "            temp_record = Fair_record[str(batch_no)][attribute]\n",
    "            for value in temp_record.keys():\n",
    "                record[attribute][int(value)].append(temp_record[value])\n",
    "    sum_record =  {'race' : {0 : {}, 1 : {}, 2: {}},\n",
    "               'male' : {0 : {}, 1 : {}}, \n",
    "               'hispanic' : {0 : {}, 1 : {}}, \n",
    "               'maritalstatus' : {-1 : {}, 0 : {}, 1 : {}, 2: {},3 : {}, 4 : {}}, \n",
    "               'language' : {0 : {}, 1 : {}, 2: {}}\n",
    "              }\n",
    "\n",
    "    for attribute in record.keys(): \n",
    "        for value in record[attribute].keys():\n",
    "            temp_record = record[attribute][value]\n",
    "            count = 0\n",
    "            temp_acc = 0.0\n",
    "            temp_prec = 0.0\n",
    "            temp_auroc = 0.0\n",
    "            for temp_matrix in temp_record:\n",
    "                temp_acc += temp_matrix['accuracy'] * temp_matrix['count'] \n",
    "                temp_prec += temp_matrix['precision'] * temp_matrix['count'] \n",
    "                temp_auroc += temp_matrix['auroc'] * temp_matrix['count']\n",
    "                count += temp_matrix['count']\n",
    "    #             record[attribute][int(value)].append(temp_record[value])\n",
    "            if count > 0 : \n",
    "                sum_record[attribute][value] = {\"accuracy\" : temp_acc/count, \n",
    "                                                \"precision\" : temp_prec/count , \n",
    "                                                \"auroc\" : temp_auroc/count}\n",
    "            else:\n",
    "                print(f\"Count is 0 for attribute :  {attribute} , category : {value}\")\n",
    "    return sum_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83401ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Fair_file_path = '/minshi/medailab/datamining/AwaizN/Student_stuff/Fair_Performance_record.json'\n",
    "Original_file_path = '/minshi/medailab/datamining/AwaizN/Student_stuff/Performance_record.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5ee262",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dirs1 = '/minshi/medailab/shilab/FairVision/Glaucoma/'\n",
    "root_dirs2 = '/minshi/medailab/shilab/FairVision/DR/'\n",
    "root_dirs = [root_dirs1, root_dirs2]\n",
    "test_dataset = build_combined_dataset(root_dirs=root_dirs, phase='test', input_size=200)\n",
    "# test_sampler = SequentialSampler(test_dataset)  # Sequential sampler\n",
    "test_loader = DataLoader(test_dataset,batch_size=500,pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fa6fe6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Pooling Current State : True\n",
      "1000\n",
      "LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "Position interpolate from 14x14 to 12x12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_logits): Identity()\n",
       "  (head): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (head_drop): Dropout(p=0, inplace=False)\n",
       "  (project_layer): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models_vit.load_pretrained_vit_base(target_size=200,global_pool=True, num_classes=3)\n",
    "custom_weights = torch.load('/minshi/medailab/datamining/AwaizN/Student_stuff/best_student_model(already).pth', map_location='cpu')  # Adjust map_location if using GPU\n",
    "model.load_state_dict(custom_weights, strict=False)\n",
    "# model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9110cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names = ['race','male', 'hispanic', 'maritalstatus', 'language']\n",
    "attribute_values = { \n",
    "   'race': [0, 1, 2],\n",
    "    'male': [0, 1],\n",
    "    'language': [0, 1, 2],\n",
    "    'hispanic': [0, 1],\n",
    "    'maritalstatus': [-1,0, 1,2,3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd6797b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8662)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8686)\n",
      "tensor(0.)\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8726)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8321)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.9171)\n",
      "tensor(0.)\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8234)\n",
      "tensor(0.)\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8983)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.9171)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8779)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8605)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8417)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Prediction start from the model\n",
      "Prediction recieved from the model\n",
      "tensor(1.8761)\n",
      "tensor(0.)\n",
      "Batch contains only one class. Setting AUROC to 0.333\n",
      "Batch contains only one class. Setting AUROC to 0.333\n"
     ]
    }
   ],
   "source": [
    "Fair_result = {}\n",
    "original_result = {}\n",
    "class_specific_tau = {0: 0.8, 1: 1.1, 2: 1.4}  # Adjust these values based on your requirements\n",
    "class_specific_theta = {0: 0.001, 1: 0.002, 2: 0.015}\n",
    "for batch_no,(data, labels, attributes) in enumerate(test_loader):\n",
    "    print(\"Prediction start from the model\")\n",
    "    with torch.no_grad():\n",
    "        Embedding = model.get_spatial_feature_maps(data)\n",
    "#         Spatial_Embedding = torch.nn.functional.interpolate(Embedding, size=(64, 64), mode='bilinear')\n",
    "        pooled_embeddings = F.adaptive_avg_pool2d(Embedding, (1, 1)).squeeze(-1).squeeze(-1)\n",
    "        predicted_tensor,_ = model(data)\n",
    "    temp_dict_fair = dict()\n",
    "    temp_dict_original = dict()\n",
    "    print(\"Prediction recieved from the model\")\n",
    "    fair_output = Fair_predicted_output(labels, predicted_tensor, pooled_embeddings, attributes, \n",
    "                                            class_specific_tau, class_specific_theta, lambda_GLIF_NRW=0.001)\n",
    "#     print(fair_output)\n",
    "#     for attribute_no in range(attributes.shape[1]):\n",
    "#         Attibute = attribute_names[attribute_no]\n",
    "#         attribute_name = [Attibute]\n",
    "    attribute_value = {Attibute : attribute_values[attribute_names[attribute_no]]}\n",
    "#         print(attribute_name)\n",
    "#         print(\"pred Label :\" + str(torch.softmax(predicted_tensor, dim=1)))\n",
    "    overall_results = evaluate_distinct_attributes(attributes, labels, predicted_tensor, attribute_names, attribute_values)\n",
    "    F_overall_results = evaluate_distinct_attributes(attributes, labels, fair_output, attribute_names, attribute_values)\n",
    "#         break\n",
    "#         temp_dict_fair[attribute_names[attribute_no]] = F_overall_results\n",
    "#         temp_dict_original[attribute_names[attribute_no]] = overall_results\n",
    "    temp_dict_fair.update(F_overall_results)\n",
    "    temp_dict_original.update(overall_results)\n",
    "    Fair_overall_result = calculate_metrics(labels.detach(), fair_output.detach())\n",
    "    UnFair_overall_result = calculate_metrics(labels.detach(), predicted_tensor.detach())\n",
    "    temp_dict_fair['Overall'] = Fair_overall_result\n",
    "    temp_dict_original['Overall'] = UnFair_overall_result\n",
    "    Fair_result[batch_no] = temp_dict_fair\n",
    "    original_result[batch_no] = temp_dict_original\n",
    "    save_dict(Fair_result, Fair_file_path)\n",
    "    save_dict(original_result, Original_file_path)\n",
    "    Fair_record = load_dict(Fair_file_path)\n",
    "#     print(eav(Fair_record))\n",
    "    Original_record = load_dict(Original_file_path)\n",
    "#     print(eav(Original_record))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26497f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy : 0.7273333333333332\n",
      "Overall Precision : 0.7573536886596446\n",
      "Overall AUROC : 0.8761363922374534\n",
      "Overall Accuracy : 0.7373333333333334\n",
      "Overall Precision : 0.7330731135574499\n",
      "Overall AUROC : 0.8573694796703628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'race_0': [0.8945186353556517, 0.8777567362332971],\n",
       " 'race_1': [0.8675337262798222, 0.8470081060197792],\n",
       " 'race_2': [0.8747767373519817, 0.8559381871782273],\n",
       " 'male_0': [0.8744718537618532, 0.8555479442771696],\n",
       " 'male_1': [0.8772443784881646, 0.8585984871608685],\n",
       " 'hispanic_0': [0.8765793351579889, 0.8577618796304949],\n",
       " 'hispanic_1': [0.8502193406340489, 0.8326452587762472],\n",
       " 'maritalstatus_-1': [0.8669838227737584, 0.8467761740686974],\n",
       " 'maritalstatus_0': [0.8826708300718905, 0.8650800904153172],\n",
       " 'maritalstatus_1': [0.8655562495211385, 0.8448161540305714],\n",
       " 'maritalstatus_2': [0.8943512996168117, 0.8751783985508284],\n",
       " 'maritalstatus_3': [0.8700527501532159, 0.8481969500546621],\n",
       " 'maritalstatus_4': [0.5046367521367521, 0.5046367521367521],\n",
       " 'language_0': [0.8759793236347047, 0.85713702110791],\n",
       " 'language_1': [0.7715398308856254, 0.756928991742076],\n",
       " 'language_2': [0.8798126523651418, 0.8613928033459316]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fair_record = load_dict(Fair_file_path)\n",
    "fair_res = eav(Fair_record)\n",
    "Original_record = load_dict(Original_file_path)\n",
    "res = eav(Original_record)\n",
    "\n",
    "\n",
    "compile_res = {}\n",
    "for attribute in fair_res.keys():\n",
    "    for value in fair_res[attribute].keys():\n",
    "        if bool(fair_res[attribute][value]) and bool(res[attribute][value]):\n",
    "            compile_res[attribute + \"_\" + str(value)] = [fair_res[attribute][value]['auroc'],res[attribute][value]['auroc']]\n",
    "            \n",
    "compile_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1794f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e54113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
